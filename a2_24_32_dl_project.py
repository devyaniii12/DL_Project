# -*- coding: utf-8 -*-
"""A2_24_32_DL_project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CVob7VYt5DKzM6RCFYjmpNS9HuzwFofc
"""

!pip install transformers datasets

from datasets import load_dataset
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, Trainer, TrainingArguments
import torch

from datasets import load_dataset
dataset = load_dataset('cnn_dailymail', '3.0.0')

dataset = load_dataset('cnn_dailymail', '3.0.0')
train_data = dataset['train'].select(range(200))
val_data = dataset['validation'].select(range(50))

model_name = 'facebook/bart-base'
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSeq2SeqLM.from_pretrained(model_name)

def preprocess(batch):
    inputs = tokenizer(batch['article'], max_length=512, truncation=True, padding='max_length')
    targets = tokenizer(batch['highlights'], max_length=128, truncation=True, padding='max_length')
    inputs['labels'] = targets['input_ids']
    return inputs

train_dataset = train_data.map(preprocess, batched=True, remove_columns=['article', 'highlights', 'id'])
val_dataset = val_data.map(preprocess, batched=True, remove_columns=['article', 'highlights', 'id'])

training_args = TrainingArguments(
    output_dir='./bart-summary-model',
    per_device_train_batch_size=2,
    per_device_eval_batch_size=2,
    num_train_epochs=2,
    logging_dir='./logs',
    evaluation_strategy='epoch',
    save_strategy='epoch',
    learning_rate=2e-5
)

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=val_dataset,
    tokenizer=tokenizer,
)
trainer.train()

model.save_pretrained('./bart-summary-model')
tokenizer.save_pretrained('./bart-summary-model')

from transformers import pipeline
summarizer = pipeline('summarization', model='./bart-summary-model', tokenizer='./bart-summary-model')

text = """
NASA has announced the discovery of a new exoplanet that closely resembles Earth in size and temperature.
The planet, named Kepler-1649c, orbits in its star's habitable zone and may support liquid water.
This breakthrough was made possible using data collected by the retired Kepler space telescope...
"""

summary = summarizer(text, max_length=100, min_length=30, do_sample=False)
print("Summary:", summary[0]['summary_text'])

from transformers import pipeline
summarizer = pipeline('summarization', model='./bart-summary-model', tokenizer='./bart-summary-model')

text = """
Convolutional Neural Networks (CNNs) are a class of deep learning models designed for processing structured grid-like data, such as images. They are highly effective for computer vision tasks like image classification, object detection, and facial recognition.
1.	A CNN consists of multiple layers that transform an input image into a feature-rich representation. The key layers include:
2.	Convolutional Layer: This layer applies filters (kernels) to detect patterns such as edges, textures, and objects. The convolution operation extracts spatial features while preserving spatial relationships.
3.	Activation Function (ReLU): After convolution, the Rectified Linear Unit (ReLU) is applied to introduce non-linearity, ensuring the network can learn complex patterns.
4.	Pooling Layer: Pooling reduces the spatial dimensions of feature maps while retaining important features. Max-pooling is commonly used to extract the most prominent values, making the model translation-invariant.
5.	Fully Connected Layer: The high-level features extracted from convolutional and pooling layers are fed into a fully connected (dense) layer, which ultimately makes predictions.
6.	Softmax or Sigmoid Activation: These functions are used in the final layer to classify the input into different categories.

"""

summary = summarizer(text, max_length=100, min_length=30, do_sample=False)
print("Summary:", summary[0]['summary_text'])

from IPython.core.display import display, HTML
from transformers import pipeline

# Load the summarizer from your fine-tuned model
summarizer = pipeline('summarization', model='./bart-summary-model', tokenizer='./bart-summary-model')

# Long article to summarize
text = """
Artificial Intelligence (AI) has rapidly become one of the most transformative technologies of the 21st century. It is revolutionizing industries ranging from healthcare and finance to entertainment and transportation. AI systems can now perform tasks that typically require human intelligence, such as recognizing speech, analyzing images, making decisions, and even generating creative content like music and art.

One of the most exciting applications of AI is in the field of healthcare. AI-powered tools are helping doctors diagnose diseases more accurately, discover new drugs faster, and provide personalized treatment recommendations based on a patient's unique genetic makeup. Meanwhile, self-driving cars, powered by AI, are changing the way we think about transportation by promising safer and more efficient travel.

However, the rise of AI also raises important ethical and social concerns. There are fears about job displacement due to automation, privacy issues from data collection, and potential misuse of AI in surveillance or warfare. As a result, many experts are calling for clear regulations and ethical frameworks to ensure that AI development remains safe, transparent, and aligned with human values.

Despite these challenges, AI continues to evolve at a rapid pace. As researchers and engineers push the boundaries of what machines can do, it is becoming increasingly important for society to stay informed and engaged in shaping the future of AI responsibly.
"""

# Generate summary
summary = summarizer(text, max_length=100, min_length=30, do_sample=False)[0]['summary_text']

# Display original text
display(HTML(f"<h4>üìÑ <u>Original Text</u>:</h4><div style='white-space: pre-wrap; font-size: 14px'>{text}</div>"))

# Display summary
display(HTML(f"<h4>üìù <u>Generated Summary</u>:</h4><div style='white-space: pre-wrap; color: green; font-size: 16px'><b>{summary}</b></div>"))

from IPython.core.display import display, HTML
from transformers import pipeline

# Load the summarizer from your fine-tuned model
summarizer = pipeline('summarization', model='./bart-summary-model', tokenizer='./bart-summary-model')

# Long article to summarize
text = """
Fingerprints are epidermal ridges and volar aspect arrangement on palms, fingers, and soles. The smaller crimson along with wrinkles on  skin over  the  palm  and  plantar aspects  is known  as  ridges. Fingerprint is an individuality principle with permanent features that cannot be replicated in an individual's entire life span. It is the most special, significant, and accurate characteristic in the human body [1, 2]. The  probability of two people having an identical pattern of fingerprints  is  one  in  64,000  million.  The  ridge pattern  of fingerprints  developed  during  the  fetal  period  do  not  change throughout  their  life  until  skin  decomposes.  The  pattern  of fingerprints  differ  widely  with  blood  groups  variation  [3,  4].  A fingerprint  is  a  representation  of  the  friction  ridge  on  all  parts. Epidermis  cornfield  layer  and  dermal  papillae  are  mainly associated with ridge patterns. During 3rd and 4th month of fetal life, primitive forms of epidermal ridges pattern could be characterized. Fingerprints  could  be  classified  as  loops,  arches,  whorl,  and composite.  The  palm  fingers  epidermal  ridges  can  be  fully developed during birth and remain unchanged for life except burns or  trauma  [5,  6].  Fingerprints, footprints,  iris scanning,  lip prints, and DNA profiling are all means of identifying person identity. The method  of examining  the impressions  of the  established friction skin  ridges is  known as  fingerprint  identification,  also known  as dactyloscopy. The palmar surface and digits  can be examined to see if the impressions are from the same finger [7].   The  presence or  absence of  inherited antigens  in  the red blood  cells of  human beings  is  classified  as  a blood  group. Rh method  and  ABO  are  two  significant  blood  groups.  Based  on plasma  antigen  existence,  ABO  blood  grouping  is  further categorized  into  A,  B,  AB,  and  O  variations  [8,  9].   Gene association with other characters complicates the genetics of blood groups.  The  higher  prevalence  of  duodenum  ulcer  in  ‚ÄúO‚Äù  blood group  population  and  stomach cancer  in  ‚ÄúA‚Äù blood  group people are  the  clinical  importance  of  varieties  in  blood  grouping.  In comparison to  the  general population,  the prevalence  of ‚ÄúO‚Äù  and ‚ÄúA‚Äù  groups  are significantly  higher  [10].  Various  Darmatoglyphics studies reported  a  significantly strong association between  blood groups and pattern of fingerprints [10-12]. Because of fingerprints implications  as  an  effective  means  of  identification,  this  study attempted to  evaluate finger  -print patterns and  their relationship with an individual blood group.
"""

# Generate summary
summary = summarizer(text, max_length=100, min_length=30, do_sample=False)[0]['summary_text']

# Display original text
display(HTML(f"<h4>üìÑ <u>Original Text</u>:</h4><div style='white-space: pre-wrap; font-size: 14px'>{text}</div>"))

# Display summary
display(HTML(f"<h4>üìù <u>Generated Summary</u>:</h4><div style='white-space: pre-wrap; color: green; font-size: 16px'><b>{summary}</b></div>"))

!zip -r bart-summary-model.zip bart-summary-model

!zip -r /content/bart-summary-model.zip bart-summary-model

!cp /content/bart-summary-model.zip /content/drive/MyDrive/